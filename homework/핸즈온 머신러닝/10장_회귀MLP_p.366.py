## p. 361

'''
회귀 MLP의 전형적인 구조

입력 뉴런 수: 특성마다 하나 (예를 들어 MNIST의 경우 28 * 28 =784)

은닉층 수 : 문제에 따라 다름, 일반적으로 1에서 5사이

은닉층의 뉴런 수: 문제에 따라 다름, 일반적으로 10에서 100사이

출력 뉴런 수: 예측 차원마다 하나

은닉층의 활성화 함수: Relu(또는 SELU)

출력층의 활성화 함수: 없음 또는 (출력이 양수일 때) Relu/softplus나 (출력 특정 범위로 제한할 때) losistic/tanh을 사용.

손실함수 : MSE(평균 제곱 오차), MAE(평균 절댓값 오차), 혹은 이 둘을 조합한 Huber(후버)를 사용
'''